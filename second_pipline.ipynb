{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import confusion_matrix, classification_report\n",
    "# from keras.utils import to_categorical\n",
    "# from keras.callbacks import EarlyStopping\n",
    "from keras.layers import LSTM, Dense\n",
    "import lazypredict\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '011/text_data/'\n",
    "\n",
    "ada_joy = data_path + 'ada_joy.csv'\n",
    "assistance_info = data_path + 'assistance_info.csv'\n",
    "gaze_positions = data_path + 'gaze_positions.csv'\n",
    "input_info = data_path + 'input_info.csv'\n",
    "joint_positions = data_path + 'joint_positions.csv'\n",
    "myo_emg = data_path + 'myo_emg.csv'\n",
    "myo_imu = data_path + 'myo_imu.csv'\n",
    "myo_ori = data_path + 'myo_ori.csv'\n",
    "pupil_cal_eye0 = data_path + 'pupil_cal_eye0.csv'\n",
    "pupil_cal_eye1 = data_path + 'pupil_cal_eye1.csv'\n",
    "pupil_eye0 = data_path + 'pupil_eye0.csv'\n",
    "pupil_eye1 = data_path + 'pupil_eye1.csv'\n",
    "robot_position = data_path + 'robot_position.csv'\n",
    "world_cal_positions = data_path + 'world_cal_positions.csv'\n",
    "\n",
    "ada_joy_df = pd.read_csv(ada_joy)\n",
    "assistance_info_df = pd.read_csv(assistance_info)\n",
    "gaze_positions_df = pd.read_csv(gaze_positions)\n",
    "input_info_df = pd.read_csv(input_info)\n",
    "joint_positions_df = pd.read_csv(joint_positions)\n",
    "myo_emg_df = pd.read_csv(myo_emg)\n",
    "myo_imu_df = pd.read_csv(myo_imu)\n",
    "myo_ori_df = pd.read_csv(myo_ori)\n",
    "pupil_cal_eye0_df = pd.read_csv(pupil_cal_eye0)\n",
    "pupil_cal_eye1_df = pd.read_csv(pupil_cal_eye1)\n",
    "pupil_eye0_df = pd.read_csv(pupil_eye0)\n",
    "pupil_eye1_df = pd.read_csv(pupil_eye1)\n",
    "robot_position_df = pd.read_csv(robot_position)\n",
    "world_cal_positions_df = pd.read_csv(world_cal_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# List of all your dataframes\n",
    "dfs = [ada_joy_df, assistance_info_df, gaze_positions_df, input_info_df, joint_positions_df, myo_emg_df, myo_imu_df, myo_ori_df, pupil_cal_eye0_df, pupil_cal_eye1_df, pupil_eye0_df, pupil_eye1_df, robot_position_df, world_cal_positions_df]\n",
    "\n",
    "\n",
    "joint_positions_df = joint_positions_df.fillna(joint_positions_df.select_dtypes(include=[np.number]).mean())\n",
    "djoint_positions_dffs = joint_positions_df.fillna(0)\n",
    "\n",
    "# Data normalization: Normalize data to have zero mean and unit variance\n",
    "# scaler = StandardScaler()\n",
    "# for df in dfs:\n",
    "#     numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "#     df[numeric_cols] = scaler.fit_transform(df[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joint_positions_df columns:  Index(['timestamp', 'world_index', 'world_index_corrected', 'mico_joint_1_pos',\n",
      "       'mico_joint_2_pos', 'mico_joint_3_pos', 'mico_joint_4_pos',\n",
      "       'mico_joint_5_pos', 'mico_joint_6_pos', 'mico_joint_finger_1_pos',\n",
      "       'mico_joint_finger_2_pos', 'mico_joint_1_vel', 'mico_joint_2_vel',\n",
      "       'mico_joint_3_vel', 'mico_joint_4_vel', 'mico_joint_5_vel',\n",
      "       'mico_joint_6_vel', 'mico_joint_finger_1_vel',\n",
      "       'mico_joint_finger_2_vel', 'mico_joint_1_eff', 'mico_joint_2_eff',\n",
      "       'mico_joint_3_eff', 'mico_joint_4_eff', 'mico_joint_5_eff',\n",
      "       'mico_joint_6_eff', 'mico_joint_finger_1_eff',\n",
      "       'mico_joint_finger_2_eff'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('joint_positions_df columns: ', joint_positions_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joint_positions_df columns:  (7024, 43)\n"
     ]
    }
   ],
   "source": [
    "joint_cols = ['mico_joint_1_pos', 'mico_joint_2_pos', 'mico_joint_3_pos', 'mico_joint_4_pos', 'mico_joint_5_pos', 'mico_joint_6_pos', 'mico_joint_finger_1_pos', 'mico_joint_finger_2_pos']\n",
    "\n",
    "for col in joint_cols:\n",
    "    joint_positions_df[col + '_acceleration'] = joint_positions_df[col].diff().diff()\n",
    "\n",
    "    joint_positions_df[col + '_jerk'] = joint_positions_df[col].diff().diff().diff()\n",
    "\n",
    "\n",
    "print('joint_positions_df columns: ', joint_positions_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: (7024, 39)\n",
      "Target Variable: ('mico_joint_1_pos_acceleration', 'mico_joint_1_pos_jerk')\n"
     ]
    }
   ],
   "source": [
    "target_variable = ('mico_joint_1_pos_acceleration', 'mico_joint_1_pos_jerk')\n",
    "\n",
    "# Identify redundant features and drop them (you may customize this based on your data)\n",
    "redundant_features = ['world_index_x', 'world_index_corrected_x', 'world_index_y', 'world_index_corrected_y']\n",
    "redundant_features = [col for col in redundant_features if col in joint_positions_df.columns]  # Check if columns exist\n",
    "joint_positions_df = joint_positions_df.drop(columns=redundant_features)\n",
    "\n",
    "# Select features and target variable\n",
    "features = joint_positions_df.drop(columns=list(target_variable))\n",
    "target = joint_positions_df[list(target_variable)]\n",
    "\n",
    "# Check for highly correlated features and drop if necessary\n",
    "correlation_matrix = features.corr()\n",
    "upper_triangle = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper_triangle.columns if any(np.abs(upper_triangle[column]) > 0.95)]\n",
    "features = features.drop(columns=to_drop)\n",
    "\n",
    "# Confirm the selected features and target variable\n",
    "print(\"Selected Features:\", features.shape)\n",
    "print(\"Target Variable:\", target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slide_window(dataset, step=1):\n",
    "    data_x, data_y = [], []\n",
    "    for i in range(len(dataset)-step-1):\n",
    "        a = dataset[i:(i+step),1]\n",
    "        data_x.append(a)\n",
    "        # data_y.append(dataset[i+ step,0])\n",
    "        data_y.append(dataset[i+step,1]) \n",
    "        \n",
    "    return np.array(data_x), np.array(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'method' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 19\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# this are selected features: joint_positions_df columns:  (7024, 43)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Selected Features: (7024, 39)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Target Variable: ('mico_joint_1_pos_acceleration', 'mico_joint_1_pos_jerk') \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# X_train.astype\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m Xtrain, Xtest, Ytrain, Ytest \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mslide_window\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m], slide_window(target\u001b[38;5;241m.\u001b[39mto_numpy, \u001b[38;5;241m3\u001b[39m)[\u001b[38;5;241m1\u001b[39m], test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.33\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     20\u001b[0m Xtrain\u001b[38;5;241m.\u001b[39mshape, Xtest\u001b[38;5;241m.\u001b[39mshape, Ytrain\u001b[38;5;241m.\u001b[39mshape, Ytest\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# geting Xval and Yval from Xtrain and Ytrain\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[60], line 3\u001b[0m, in \u001b[0;36mslide_window\u001b[1;34m(dataset, step)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mslide_window\u001b[39m(dataset, step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      2\u001b[0m     data_x, data_y \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m-\u001b[39mstep\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      4\u001b[0m         a \u001b[38;5;241m=\u001b[39m dataset[i:(i\u001b[38;5;241m+\u001b[39mstep),\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      5\u001b[0m         data_x\u001b[38;5;241m.\u001b[39mappend(a)\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'method' has no len()"
     ]
    }
   ],
   "source": [
    "# this are selected features: joint_positions_df columns:  (7024, 43)\n",
    "# Selected Features: (7024, 39)\n",
    "# Target Variable: ('mico_joint_1_pos_acceleration', 'mico_joint_1_pos_jerk') \n",
    "\n",
    "# Split data into train and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, shuffle=False)\n",
    "# Normalize data\n",
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "\n",
    "# X_train = np.array(X_train)\n",
    "# X_test = np.array(X_test)\n",
    "# y_train = np.array(y_train)\n",
    "# y_test = np.array(y_test)\n",
    "\n",
    "# X_train.astype\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(slide_window(features.to_numpy, 3)[0], slide_window(target.to_numpy, 3)[1], test_size=0.33, random_state= True)\n",
    "Xtrain.shape, Xtest.shape, Ytrain.shape, Ytest.shape\n",
    "# geting Xval and Yval from Xtrain and Ytrain\n",
    "Xtest, Xval, Ytest, Yval = train_test_split(Xtest, Ytest, test_size=0.5, random_state= True)\n",
    "Xtrain.shape, Xval.shape, Ytrain.shape, Yval.shape\n",
    "Ytrain,Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "# clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "# models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# print(models)\n",
    "# models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5619, 1, 2)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape data for LSTM model\n",
    "X_train = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.values.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "y_train = y_train.values.reshape((y_train.shape[0], 1, y_train.shape[1]))\n",
    "y_test = y_test.values.reshape((y_test.shape[0], 1, y_test.shape[1]))\n",
    "\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "22/22 [==============================] - 3s 16ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 2/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 3/1000\n",
      "22/22 [==============================] - 0s 9ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 4/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 5/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 6/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 7/1000\n",
      "22/22 [==============================] - 0s 9ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 8/1000\n",
      "22/22 [==============================] - 0s 9ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 9/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 10/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 11/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 12/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 13/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 14/1000\n",
      "22/22 [==============================] - 0s 9ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 15/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 16/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 17/1000\n",
      "22/22 [==============================] - 0s 9ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 18/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 19/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 20/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 21/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 22/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 23/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 24/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 25/1000\n",
      "22/22 [==============================] - 0s 9ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 26/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 27/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 28/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 29/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 30/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 31/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 32/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 33/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 34/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 35/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 36/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 37/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 38/1000\n",
      "22/22 [==============================] - 0s 9ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 39/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 40/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 41/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 42/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 43/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 44/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 45/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 46/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 47/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 48/1000\n",
      "22/22 [==============================] - 0s 9ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 49/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 50/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 51/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 52/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 53/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 54/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan\n",
      "Epoch 55/1000\n",
      " 8/22 [=========>....................] - ETA: 0s - loss: nan - mean_squared_error: nan - mean_absolute_percentage_error: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m es\u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, baseline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     18\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_absolute_percentage_error\u001b[39m\u001b[38;5;124m'\u001b[39m]) \n\u001b[1;32m---> 19\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\test\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\test\\.conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\test\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\test\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\test\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\test\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\test\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\test\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\test\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "num_epochs =1000\n",
    "batch_size=256\n",
    "sequence_length = X_train.shape[1]\n",
    "input_dim= X_train.shape[2]\n",
    "output_dim= y_train.shape[2]\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, input_shape=(sequence_length, input_dim)))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Dropout (0.2))\n",
    "model.add(LSTM(128, return_sequences=False, input_shape=(sequence_length, input_dim)))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Dropout (0.2))\n",
    "# model.add(Dense(1))\n",
    "model.add((Dense (output_dim)))\n",
    "model.add(Activation(\"linear\"))\n",
    "es= EarlyStopping(monitor='val_loss', min_delta=0, patience=6, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=['mean_squared_error','mean_absolute_percentage_error']) \n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "141/141 [==============================] - 4s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      "141/141 [==============================] - 1s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/10\n",
      "141/141 [==============================] - 1s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/10\n",
      "141/141 [==============================] - 1s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/10\n",
      "141/141 [==============================] - 1s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/10\n",
      "141/141 [==============================] - 1s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/10\n",
      "141/141 [==============================] - 1s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/10\n",
      "141/141 [==============================] - 1s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/10\n",
      "141/141 [==============================] - 1s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/10\n",
      "141/141 [==============================] - 1s 8ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24d6e68da30>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# X_train_scaled = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "# '''\n",
    "# Model building\n",
    "num_features = X_train.shape[2]\n",
    "num_outputs = y_train.shape[2]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))  # Add dropout for regularization\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(num_outputs))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Model training\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1, validation_split=0.2)\n",
    "# '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 1s 4ms/step\n",
      "44/44 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m test_predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m train_rmse \u001b[38;5;241m=\u001b[39m \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m test_rmse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test, test_predictions, squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining RMSE:\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_rmse)\n",
      "File \u001b[1;32mc:\\Users\\test\\.conda\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\test\\.conda\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_regression.py:474\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    405\u001b[0m     {\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    415\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m, squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    416\u001b[0m ):\n\u001b[0;32m    417\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Mean squared error regression loss.\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \n\u001b[0;32m    419\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;124;03m    0.825...\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 474\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    477\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    478\u001b[0m     output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32mc:\\Users\\test\\.conda\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_regression.py:100\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;124;03m    correct keyword.\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     99\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m--> 100\u001b[0m y_true \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\test\\.conda\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    953\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    954\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    955\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    956\u001b[0m         )\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 959\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    967\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mc:\\Users\\test\\.conda\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\test\\.conda\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    172\u001b[0m     )\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Predict on the training set\n",
    "train_predictions = model.predict(X_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "train_rmse = mean_squared_error(y_train, train_predictions, squared=False)\n",
    "test_rmse = mean_squared_error(y_test, test_predictions, squared=False)\n",
    "\n",
    "print(\"Training RMSE:\", train_rmse)\n",
    "print(\"Testing RMSE:\", test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5619, 41), (7024, 43))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# import numpy as np\n",
    "\n",
    "# # Assuming 'target' is the column you want to predict\n",
    "# X = joint_positions_df.drop(list(target_variable), axis=1)\n",
    "# y = joint_positions_df[list(target_variable)]\n",
    "\n",
    "# # Split data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# # Reshape input to be 3D [samples, timesteps, features]\n",
    "# # X_train = np.reshape(X_train.values, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "# # X_test = np.reshape(X_test.values, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# X_train.shape, joint_positions_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
